from fastapi import APIRouter, HTTPException, Request
from datetime import datetime
import subprocess
import os
from models.alert_model import Alert
from utils.migration_util import load_config

router = APIRouter()

triggeredMigrations = []
base_log_path = "/home/ubuntu/contMigration_logs"
config = load_config()

@router.post("/alert")
async def handle_alerts(alert: Alert):
    for rule_config in config.config:
        if alert.rule == rule_config.rule and alert.output_fields.k8s_pod_name not in triggeredMigrations:
            if rule_config.action == "migrate":
                return await trigger_migration(alert, rule_config.forensic_analysis, rule_config.AI_suggestion)
            elif rule_config.action == "log":
                handle_log(alert)
                return {"message": "Event logged"}

async def trigger_migration(alert: Alert, forensic_analysis: bool = False, AI_suggestion: bool = False):
    log_path = f"{base_log_path}/{alert.output_fields.container_name}/{alert.output_fields.k8s_pod_name}"
    os.makedirs(log_path, exist_ok=True)
    with open(f"{log_path}/migration_log.txt", "w") as file:
        file.write(f"Migration log of automated container migration of {alert.output_fields.k8s_pod_name}\n")
        file.write(f"Migration is triggered because of falco rule of:\n{alert.rule}\nreceived on {alert.hostname}\n")
        file.write(f"Migration is triggered at {datetime.now()}\n\n")
    
    if forensic_analysis:
        with open(f"{log_path}/migration_log.txt", "w") as file:
            file.write(f"Forensic report of automated container migration of {alert.output_fields.k8s_pod_name}\n")
            file.write(f"Migration is triggered at {datetime.now()}\n\n")

    try:
        subprocess.Popen(["/home/ubuntu/meierm78/ContMigration-VT1/scripts/migration/single-migration.sh", alert.output_fields.k8s_pod_name])
        return {"message": "Migration task has been started"}

    except subprocess.CalledProcessError as e:
        raise HTTPException(status_code=500, detail=f"Error executing script: {e.stderr}")

def handle_log(alert: Alert):
    log_path = f"{base_log_path}/{alert.output_fields.container_name}/{alert.output_fields.k8s_pod_name}"
    os.makedirs(log_path, exist_ok=True)
    log_file = os.path.join(log_path, "event_log.txt")
    if not os.path.exists(log_file):
        with open(log_file, "w") as file:
            file.write(f"Log of events generated by Falco on {alert.output_fields.k8s_pod_name}\n")
            file.write(f"{datetime.now()}: Event received. Rule: {alert.rule}\n")
    else:
        with open(log_file, "a") as file:
            file.write(f"{datetime.now()}: Event received. Rule: {alert.rule}\n")

@router.post("/migrate")
async def migrate_pod(request: Request):
    body = await request.json()
    print(f"Request body: ", body)
    #Currently source and target are not used because migration is always from cluster1 to cluster2
    source_cluster = body.get("source_cluster")
    target_cluster = body.get("target_cluster")
    
    pod_name = body.get("pod_name")
    print(f"Pod name", pod_name)
    #TODO: Implement the logic to generate forensic report and AI suggestions
    generate_forensic_report = body.get("forensic_analysis")
    generate_AI_suggestion = body.get("AI_suggestion")

    return await trigger_migration(pod_name)